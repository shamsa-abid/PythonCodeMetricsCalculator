{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM6fQPL3iOnd",
        "outputId": "727d1ee9-e792-4cd1-9189-b2d34b4852c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friedman's test statistic: 308.88266953713685, p-value: 1.0211782217894384e-63\n",
            "Wilcoxon test (HumanEval_LOC vs GPT3.5S_LOC): stat=502.0, p-value=1.420628067299295e-22\n",
            "Wilcoxon test (HumanEval_LOC vs GPT3.5I): stat=4588.5, p-value=0.318894564695125\n",
            "Wilcoxon test (HumanEval_LOC vs GPT3.5E): stat=3651.0, p-value=0.5751421274133739\n",
            "Wilcoxon test (HumanEval_LOC vs GPT4S): stat=3352.5, p-value=8.216095195734727e-05\n",
            "Wilcoxon test (HumanEval_LOC vs GPT4I): stat=3055.0, p-value=0.003502404544579744\n",
            "Wilcoxon test (HumanEval_LOC vs GPT4E): stat=2047.5, p-value=7.138259819360276e-07\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import friedmanchisquare, wilcoxon\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"LOC_StatisticalEvaluationResults.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract LOC values as separate groups for analysis\n",
        "human_eval = data[\"HumanEval_LOC\"]\n",
        "gpt35s = data[\"GPT3.5S_LOC\"]\n",
        "gpt35i = data[\"GPT3.5I\"]\n",
        "gpt35e = data[\"GPT3.5E\"]\n",
        "gpt4s = data[\"GPT4S\"]\n",
        "gpt4i = data[\"GPT4I\"]\n",
        "gpt4e = data[\"GPT4E\"]\n",
        "\n",
        "# Perform Friedman's test\n",
        "stat, p_value = friedmanchisquare(human_eval, gpt35s, gpt35i, gpt35e, gpt4s, gpt4i, gpt4e)\n",
        "print(f\"Friedman's test statistic: {stat}, p-value: {p_value}\")\n",
        "\n",
        "\n",
        "# Iterate through all pairwise combinations if needed\n",
        "from itertools import combinations\n",
        "\n",
        "models = [\"GPT3.5S_LOC\", \"GPT3.5I\", \"GPT3.5E\", \"GPT4S\", \"GPT4I\", \"GPT4E\"]\n",
        "human_eval_column = \"HumanEval_LOC\"\n",
        "\n",
        "\n",
        "for model in models:\n",
        "    stat, p = wilcoxon(data[human_eval_column], data[model])\n",
        "    print(f\"Wilcoxon test ({human_eval_column} vs {model}): stat={stat}, p-value={p}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import friedmanchisquare, wilcoxon\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"CC_StatisticalEvaluationResults.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract LOC values as separate groups for analysis\n",
        "human_eval = data[\"HumanEval_Cyclomatic Complexity\"]\n",
        "gpt35s = data[\"GPT3.5S_Cyclomatic Complexity\"]\n",
        "gpt35i = data[\"GPT3.5I\"]\n",
        "gpt35e = data[\"GPT3.5E\"]\n",
        "gpt4s = data[\"GPT4S\"]\n",
        "gpt4i = data[\"GPT4I\"]\n",
        "gpt4e = data[\"GPT4E\"]\n",
        "\n",
        "# Perform Friedman's test\n",
        "stat, p_value = friedmanchisquare(human_eval, gpt35s, gpt35i, gpt35e, gpt4s, gpt4i, gpt4e)\n",
        "print(f\"Friedman's test statistic: {stat}, p-value: {p_value}\")\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "models = [\"GPT3.5S_Cyclomatic Complexity\", \"GPT3.5I\", \"GPT3.5E\", \"GPT4S\", \"GPT4I\", \"GPT4E\"]\n",
        "human_eval_column = \"HumanEval_Cyclomatic Complexity\"\n",
        "\n",
        "\n",
        "for model in models:\n",
        "    stat, p = wilcoxon(data[human_eval_column], data[model])\n",
        "    print(f\"Wilcoxon test ({human_eval_column} vs {model}): stat={stat}, p-value={p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL_y5ScFynR1",
        "outputId": "73988d66-2a89-4904-991c-44cf63be73d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friedman's test statistic: 19.429813880675635, p-value: 0.003496090809900352\n",
            "Wilcoxon test (HumanEval_Cyclomatic Complexity vs GPT3.5S_Cyclomatic Complexity): stat=1852.0, p-value=0.2552544850155303\n",
            "Wilcoxon test (HumanEval_Cyclomatic Complexity vs GPT3.5I): stat=2121.0, p-value=0.8007871137740373\n",
            "Wilcoxon test (HumanEval_Cyclomatic Complexity vs GPT3.5E): stat=1148.0, p-value=0.01378374602863343\n",
            "Wilcoxon test (HumanEval_Cyclomatic Complexity vs GPT4S): stat=1343.0, p-value=0.12872155602923252\n",
            "Wilcoxon test (HumanEval_Cyclomatic Complexity vs GPT4I): stat=1305.0, p-value=0.01973004103675469\n",
            "Wilcoxon test (HumanEval_Cyclomatic Complexity vs GPT4E): stat=1875.5, p-value=0.00473501481561283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import friedmanchisquare, wilcoxon\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"MI_StatisticalEvaluationResults.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract LOC values as separate groups for analysis\n",
        "human_eval = data[\"HumanEval_Maintainability Index\"]\n",
        "gpt35s = data[\"GPT3.5S_Maintainability Index\"]\n",
        "gpt35i = data[\"GPT3.5I\"]\n",
        "gpt35e = data[\"GPT3.5E\"]\n",
        "gpt4s = data[\"GPT4S\"]\n",
        "gpt4i = data[\"GPT4I\"]\n",
        "gpt4e = data[\"GPT4E\"]\n",
        "\n",
        "# Perform Friedman's test\n",
        "stat, p_value = friedmanchisquare(human_eval, gpt35s, gpt35i, gpt35e, gpt4s, gpt4i, gpt4e)\n",
        "print(f\"Friedman's test statistic: {stat}, p-value: {p_value}\")\n",
        "\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "models = [\"GPT3.5S_Maintainability Index\", \"GPT3.5I\", \"GPT3.5E\", \"GPT4S\", \"GPT4I\", \"GPT4E\"]\n",
        "human_eval_column = \"HumanEval_Maintainability Index\"\n",
        "\n",
        "for model in models:\n",
        "    stat, p = wilcoxon(data[human_eval_column], data[model])\n",
        "    print(f\"Wilcoxon test ({human_eval_column} vs {model}): stat={stat}, p-value={p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XKYQHL97qHj",
        "outputId": "e01bcf56-d921-48f7-c199-061d5fd277f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friedman's test statistic: 170.59518599562415, p-value: 3.3631924772573337e-34\n",
            "Wilcoxon test (HumanEval_Maintainability Index vs GPT3.5S_Maintainability Index): stat=467.0, p-value=1.8811418083423235e-22\n",
            "Wilcoxon test (HumanEval_Maintainability Index vs GPT3.5I): stat=4566.0, p-value=0.05288720486079904\n",
            "Wilcoxon test (HumanEval_Maintainability Index vs GPT3.5E): stat=2932.0, p-value=3.005958655961956e-07\n",
            "Wilcoxon test (HumanEval_Maintainability Index vs GPT4S): stat=2272.0, p-value=1.8473281691106275e-08\n",
            "Wilcoxon test (HumanEval_Maintainability Index vs GPT4I): stat=2507.5, p-value=4.791099099169721e-06\n",
            "Wilcoxon test (HumanEval_Maintainability Index vs GPT4E): stat=2308.0, p-value=8.503161857581495e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import friedmanchisquare, wilcoxon\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"CogC_StatisticalEvaluationResults.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract LOC values as separate groups for analysis\n",
        "human_eval = data[\"HumanEval_Complexity\"]\n",
        "gpt35s = data[\"GPT3.5S\"]\n",
        "gpt35i = data[\"GPT3.5I\"]\n",
        "gpt35e = data[\"GPT3.5E\"]\n",
        "gpt4s = data[\"GPT4S\"]\n",
        "gpt4i = data[\"GPT4I\"]\n",
        "gpt4e = data[\"GPT4E\"]\n",
        "\n",
        "# Perform Friedman's test\n",
        "stat, p_value = friedmanchisquare(human_eval, gpt35s, gpt35i, gpt35e, gpt4s, gpt4i, gpt4e)\n",
        "print(f\"Friedman's test statistic: {stat}, p-value: {p_value}\")\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "models = [\"GPT3.5S\", \"GPT3.5I\", \"GPT3.5E\", \"GPT4S\", \"GPT4I\", \"GPT4E\"]\n",
        "human_eval_column = \"HumanEval_Complexity\"\n",
        "\n",
        "for model in models:\n",
        "    stat, p = wilcoxon(data[human_eval_column], data[model])\n",
        "    print(f\"Wilcoxon test ({human_eval_column} vs {model}): stat={stat}, p-value={p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpMjp6aSiqHA",
        "outputId": "8199da05-1ccc-4450-9368-ac37abd337a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friedman's test statistic: 108.95971074380202, p-value: 3.3657445768802907e-21\n",
            "Wilcoxon test (HumanEval_Complexity vs GPT3.5S): stat=2247.0, p-value=0.3367755904310903\n",
            "Wilcoxon test (HumanEval_Complexity vs GPT3.5I): stat=2255.5, p-value=0.5438883799048799\n",
            "Wilcoxon test (HumanEval_Complexity vs GPT3.5E): stat=651.0, p-value=7.051189198915836e-08\n",
            "Wilcoxon test (HumanEval_Complexity vs GPT4S): stat=1675.5, p-value=0.016327949435260492\n",
            "Wilcoxon test (HumanEval_Complexity vs GPT4I): stat=1028.5, p-value=7.954093372341784e-06\n",
            "Wilcoxon test (HumanEval_Complexity vs GPT4E): stat=961.0, p-value=1.0125017061754096e-09\n"
          ]
        }
      ]
    }
  ]
}